{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1> ILI-286 - Laboratorio #1 </h1>\n",
    "    <h2> Computación numérica de vectores propios aplicados a PCA </h2>\n",
    "</center>\n",
    "\n",
    "| Nombre | Rol | Email |\n",
    "| :----- | :-- | :---- |\n",
    "| Marco Rojas | 201073005-0 | marco.rojaso@alumnos.usm.cl |\n",
    "| Hernán Vargas | 201073009-3 | hernan.vargas@alumnos.usm.cl |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabla de contenidos\n",
    "* [Introducción](#intro)\n",
    "* [Desarrollo y analisís de resultados:](#desarrollo)\n",
    " 1. [Power Iteration y Rayleigh Quotient](#de1)\n",
    " 2. [Naive k-first eigen finder](#de2)\n",
    " 3. [Clever k-first eigen finder](#de3)\n",
    " 4. [Modificación a Normalized Simultaneous Iteration](#de4)\n",
    " 5. [Power iteration v/s Rayleigh Quotient iteration](#de5)\n",
    " 6. [Naive k-eigen finder v/s Clever k-eigen finder v/s k-eigen Normalized Simultaneous Iteration](#de6)\n",
    " 7. [Todos los valores y vectores propios](#de7)\n",
    "* [Concluciones](#Concluciones)\n",
    "* [Referencias](#Referencias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='intro' />\n",
    "## Introducción\n",
    "En este laboratorio se analizarán diversos algoritmos para el cálculo de valores y vectores propios.\n",
    "De su implementación se calculará su complejidad y se harán comparaciones para obtener concluciones sobre su desempeño y exactitud.\n",
    "\n",
    "Como muestra se utilizará un *dataset* de 700 mediciones con 2500 caracteristicas. \n",
    "Como muchos algoritmos requieren una matriz cuadrada para operar se trabajará sobre la matriz de covarianzas que resultará ser $A_{n\\times n}$ con $n=2500$, pues el calculo de los valores propios de ésta es muy útil para el *Principal Component Analisis* y lograr identificar los componentes principales.\n",
    "\n",
    "Como notamos, al trabajar con una matriz de $2500\\times 2500$ los tiempos que requerirán nuestros algoritmos para encontrar todos los valores y vectores propios serán muy largos así que buscamos metodos que evadan este proceso y solo encuentren los más relevantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='desarrollo'/>\n",
    "## Desarrollo y analisís de resultados\n",
    "\n",
    "Debemos comenzar cargando las bibliotecas y datos necesarios. Además se definirán algunas variables que se usarán más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#Para utilizar %memit\n",
    "%load_ext memory_profiler\n",
    "\n",
    "dataset = np.load(\"arcene.npy\")\n",
    "sigma_x = np.dot((1/(1-dataset.shape[1]))*np.transpose(dataset), dataset)\n",
    "\n",
    "def normalize(A):\n",
    "    return np.divide(A,(np.linalg.norm(A)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Además como se calcularán las complejidades de varios algoritmos se debe tener en cuenta lo siguiente:\n",
    "\n",
    "La multiplicación de una matriz $A_{n\\times m}$ por $B_{m\\times p}$ tiene complejidad $O(nmp)$. En este caso trabajamos con matrices cuadradas y vectores así que nuestra complejidad del producto matriz - vector será: $O(n^2)$\n",
    "\n",
    "La normalización de una matriz $A_{n\\times m}$ incluye una multiplicación de matriz por escalar y una división por la norma de una matriz. \n",
    "La multiplicación y la división tendrá complejidad $O(n^2)$ para las matrices $A_{n\\times n}$.\n",
    "La norma que consiste en elevar cada elemento ($O(n^2)$), sumarlos ($O(n^2)$) y sacar la raíz cuadráda ($\\sim O(n)$) de esta suma. Así la norma tambien tendrá complejidad de $O(n^2)$ y por ello el proceso de normalización tendrá complejidad de $O(n^2)$\n",
    "\n",
    "\n",
    "La normalización de una matriz $A_{n\\times m}$ incluye una multiplicación de matriz por escalar y una división por la norma de una matriz. \n",
    "La multiplicación y la división tendrá complejidad $O(n^2)$ para las matrices $A_{n\\times n}$.\n",
    "La norma que consiste en elevar cada elemento ($O(n^2)$), sumarlos ($O(n^2)$) y sacar la raíz cuadráda ($\\sim O(n)$) de esta suma. Así la norma tambien tendrá complejidad de $O(n^2)$ y por ello el proceso de normalización tendrá complejidad de $O(n^2)$\n",
    "\n",
    "Además podemos notar que la complejidad de calcular la transpuesta de $A_{n\\times n}$ será $O(n^2)$\n",
    "\n",
    "Por último, la complejidad de `numpy.linalg.solve` es de $O(n^3)$ pues utiliza el algoritmo *LAPACK*[[1](#ref1)] podemos ver su complejidad en [[2](#ref2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='de1'/>\n",
    "### 1.- Power Iteration y Rayleigh Quotient Iteration\n",
    "\n",
    "Los siguientes algoritmos requieren una matriz $A_{n\\times n}$.\n",
    "Opcionalmente pueden recibir el vector inicial $x_{n\\times 1}$ (por defecto $[1 \\dots 1]^{T}$) y un número máximo de iteraciones (por defecto $1000$).\n",
    "\n",
    "Adicionalmente *Rayleigh Quotient Iteration* necesita una función que resuelva sistemas de ecuaciones $Ax = b$, por ello tiene como argumento opcional una función (`solve`) que reciba la tupla $(A,b)$ y retorne $x$. Por defecto se utiliza `numpy.linalg.solve` pues es la más general.\n",
    "\n",
    "Ambos algoritmos retornan una tupla con el valor y vector propio dominante: $(\\lambda, \\vec{v})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def power_iteration(A, x=None, max_iter=1000):\n",
    "    #Comprueba las dimensiones de x.\n",
    "    if x is None: x = np.ones([A.shape[0],1])\n",
    "    elif A.shape[0] != x.shape[0]: raise ValueError(\"Initial vector error.\")\n",
    "    #Bucle de resolución.\n",
    "    lamb_old = False\n",
    "    for j in range(1, max_iter):\n",
    "        u = normalize(x)\n",
    "        x = np.dot(A,u)\n",
    "        lamb = np.dot(np.transpose(u),x)\n",
    "        if (lamb == lamb_old): break\n",
    "        lamb_old = lamb\n",
    "    u = normalize(x)\n",
    "    return lamb[0,0], u\n",
    "\n",
    "def rayleigh_quotient_iteration(A, x=None, max_iter=1000, solve=np.linalg.solve):\n",
    "    #Comprueba las dimensiones de x.\n",
    "    if x is None: x = np.ones([A.shape[0],1])\n",
    "    elif A.shape[0] != x.shape[0]: raise ValueError(\"Initial vector error.\")\n",
    "    #Bucle de resolución.\n",
    "    I = np.identity(A.shape[0])\n",
    "    lamb_old = False\n",
    "    for i in range(1, max_iter):\n",
    "        u = normalize(x)\n",
    "        lamb = np.dot(np.dot(np.transpose(u), A), u)\n",
    "        C = A - lamb*I\n",
    "        try:\n",
    "            x = solve(C, u)\n",
    "        except np.linalg.LinAlgError as e:\n",
    "            if(str(e) == \"Singular matrix\"): break \n",
    "            else: raise\n",
    "        if (lamb == lamb_old): break\n",
    "        lamb_old = lamb\n",
    "    u = normalize(x)\n",
    "    return lamb[0,0], u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Complejidad algoritmo Power Iteracion: \n",
    "En el bucle principal de *Power Iteration* se realiza una normalización, dos productos matriz - vector y una transpuesta, así su complejidad será: $k(O(n^2) + 2O(n^2) + O(n^2)) = O(kn^2)$\n",
    "     \n",
    "Como vemos, la complejidad de *Power Iteration* viene dada principalmente por la cantidad de iteraciones $k$ que alcance a realizar antes de converger. Como la tasa de convergencia de este algoritmo es lineal se espera que $k$ sea grande.\n",
    "     \n",
    "     \n",
    "#### b) Complejidad algoritmo Rayleigh Quotient Iteration:\n",
    "El bucle principal de *Rayleigh Quotient Iteration* efectua una normalización, una transpuesta, dos productos puntos y un *solve*, así su complejidad estará dada por: $k(4O(n^2) + O(n^3)) = O(kn^3)$\n",
    "     \n",
    "$k$ al igual que en el caso anterior representa la cantidad de iteraciones que alcanza a realizar el algoritmo, este $k$ será mucho menor (convergencia cuadrática) que en *power iteration* pues el algoritmo hace converger el vector propio más rapidamente especialmente cuando la matris $A$ es simetrica (convergencia cúbica).\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='de2'/>\n",
    "### 2.- Naive k-first eigen finder\n",
    "#### a) Correctitud:\n",
    "\n",
    "Llamemos $B = A - \\lambda_1 v_1 v_1^T$, supongamos $A$ simetrica y por ello sus vectores propios ortogonales. Calcularemos los vectores y valores propios de B:\n",
    "$$ B v_i = (A - \\lambda_1 v_1 v_1^T)v_i$$\n",
    "$$ B v_i = Av_i - \\lambda_1 v_1 v_1^Tv_i$$\n",
    "\n",
    "Luego, digamos $v_i$ unitario por lo que para $i=1$ tenemos $ v_1^T v_i = 1$ y  para $i\\neq 1$ tenemos que $ v_1^T v_i = 0 $ \n",
    "\n",
    "Así, $B v_i = \\lambda_i v_i $ para $i=2:n$\n",
    "\n",
    "Es decir, los valores y vectores propios de $B$ con respecto a $A$ son iguales a excepción del primer valor propio de $B$ que es 0 a diferencia de $A$. Entonces podemos usar ésta propiedad para calcular los valores propios dominantes i-ésimos de $A$ con *Power Iteration* u otro algoritmo de búsqueda de valor propio dominante.\n",
    "\n",
    "#### b) Complejidad del algoritmo kEigenFinder:\n",
    "En el bucle principal de `kEigenFinder` se realiza una transpuesta, un producto punto, una resta y un *power iteration*,\n",
    "así, suponiendo que $k_1$ es el número de valores y vectores propios a obtener y $k_2$ es el promedio de iteraciones de *power iteration* tenemos que la complejidad del algoritmo será: $k_1(3O(n^2 + O(k_2n^2))) = O(k_1k_2n^2)$\n",
    "\n",
    "#### c) Implementación:\n",
    "`kEigenFinder` toma como argumento una matriz simetrica $A_{n\\times n}$. Opcionalmente un número $k$ de valores y vectores propios a obtener (por defecto todos) y un número máximo de iteraciones `max_iter` y vector $p$ inicial para cada ejecución de *power iteration*.\n",
    "\n",
    "Retorna un `array` con valores propios y una matriz con vectores propios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def kEigenFinder(A, k = None, p = None, max_iter=1000):\n",
    "    if p is None: p = np.ones([A.shape[0],1])\n",
    "    elif A.shape[0] != p.shape[0]: raise ValueError(\"Initial vector error.\")\n",
    "    if k is None: k = A.shape[0]\n",
    "    elif k > A.shape[0]: raise ValueError(\"k is out of range.\")\n",
    "    \n",
    "    lamb = np.zeros([p.shape[0],1])\n",
    "    l = 0\n",
    "    v_finales = np.zeros([p.shape[0], p.shape[0]])\n",
    "    v = np.zeros([p.shape[0], 1])\n",
    "    for j in range(0, k):\n",
    "        A = A-l*np.dot(v,v.transpose())\n",
    "        l, v = power_iteration(A, p, max_iter)\n",
    "        v_finales[:,[j]] = v\n",
    "        lamb[j] = l\n",
    "    return lamb, v_finales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='de3'/>\n",
    "### 3.- Clever k-first eigen finder\n",
    "#### a) Correctitud\n",
    "\n",
    "Llamemos $B = A^p - \\lambda_1^p v_1 v_1^T$, supongamos $A$ simétrica y por ello sus vectores propios ortogonales. Calcularemos los vectores y valores propios de B:\n",
    "$$ B v_i = (A^p - \\lambda_1^p v_1 v_1^T)v_i$$\n",
    "$$ B v_i = A^p v_i - \\lambda_1^p v_1 v_1^Tv_i$$\n",
    "\n",
    "Luego, sabemos que $v_i$ es unitario y ortogonal a los otros $v_j$ por lo que para $i=1$ tenemos $ v_1^T v_i = 1$ y  para $i\\neq 1$ tenemos que $ v_1^T v_i = 0 $ \n",
    "\n",
    "Así, $B v_i = \\lambda_i^p v_i $ para $i=2:n$\n",
    "\n",
    "Es decir, los valores y vectores propios de $B$ con respecto a $A$ son los mismos elevados a $p$ a excepción del primer valor propio de $B$, pero este no es tomado en el algoritmo ya que en ese caso se hace $lambda = 0$. Luego así se van calculado los valores y vectores propios uno a uno por cada iteración.\n",
    "#### b) Complejidad algoritmo kEigenFinderPP:\n",
    "Con una matriz $A_{n\\times n}$ tenemos que la complejidad estará dada por las operaciones dentro del bucle principal. Tenemos cuatro productos matriz vector, dos transpuestas, una normalización y una resta.\n",
    "\n",
    "Así,la complejidad de kEigenFinderPP para encontrar $k$ valores propios será: \n",
    "    $k(4n^2 + 2n^2 + 2n^2) ~= O(kn^2)$\n",
    "\n",
    "#### c) Implementación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def kEigenFinderPP(A, p = 5, k = None):\n",
    "    if k is None: k = A.shape[0]\n",
    "    elif k > A.shape[0]: raise ValueError(\"k is out of range.\")\n",
    "    #Listas donde se guardarán los resulados.\n",
    "    lamb = [None] * k\n",
    "    v    = [None] * k\n",
    "    #Valores iniciales.\n",
    "    A_p  = np.linalg.matrix_power(A, p)\n",
    "    #x = np.random.random([A.shape[0],1])\n",
    "    x = np.ones([A.shape[0],1])\n",
    "    #Bucle de resolución.\n",
    "    for i in range(0, k):\n",
    "        x = np.dot(A_p, x)\n",
    "        v[i] = normalize(x)\n",
    "        lamb[i]= np.dot(np.dot(np.transpose(v[i]), A), v[i])[0,0]\n",
    "        A_p = A_p - lamb[i]**p * np.dot(v[i], np.transpose(v[i])) #Esto se ejecuta una vez demás\n",
    "    return lamb, v\n",
    "\n",
    "A = np.matrix([[3,4,5],\n",
    "               [4,2,1],\n",
    "               [5,1,8]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='de4'/>\n",
    "### 4.- Modificación a Normalized Simultaneous Iteration\n",
    "#### a) ¿Que debemos modificar?\n",
    "Para lograr que Normalized Simultaneous Iteration sólo nos entregue los $k$ primeros valores y vectores propios sin hacer cálculos de más, debemos lograr que $diag((Q' \\cdot A) \\cdot Q)$ nos entregue sólo $k$ elementos.\n",
    "Para esto $(Q' \\cdot A)\\cdot Q$ debe ser una matriz de $k \\times k$  por lo cual $Q$ no debe ser de $m\\times m$, si no que de $m \\times k$ de manera que al hacer $Q' \\cdot A$ obtengamos una matriz de $k \\times m$ y obtengamos la anterior matriz de $k \\times k$ en $(Q' \\cdot A) \\cdot Q$.\n",
    "\n",
    "Entonces para lograr esto truncamos nuestra matriz inicial $Q$ a $Q =[:,0:k]$ permitiendo así solo calcular valores para obtener nuestros k valores propios.\n",
    "#### b) Complejidad computacional\n",
    "La complejidad es la de hacer la factorización QR $p$ veces:\n",
    "$$ p \\frac {2} {3} n^3 = O(pn^3)$$\n",
    "#### c) Implementación\n",
    "El algorirtmo *normalized_simultaneous_iteration_q* recibe como parámetros una matriz $A_{n\\times n}$, un número $k$ de valores propios a calcular (por defecto todos) y opcionalmente una cantidad máxima de iteraciones (por defecto 1000)\n",
    "\n",
    "Retorna una lista con los valores propios requeridos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalized_simultaneous_iteration(A, max_iter=1000):\n",
    "    Q = np.identity(A.shape[0])\n",
    "    for j in range (1,max_iter):\n",
    "        Q, R = np.linalg.qr(np.dot(A,Q))\n",
    "    return np.diag(np.dot(np.dot(np.transpose(Q), A),Q))\n",
    "\n",
    "def normalized_simultaneous_iteration_q(A, k=None, max_iter=1000):\n",
    "    if k == None: k = A.shape[0]\n",
    "    elif k > A.shape[0]: raise ValueError(\"k is out of range.\")\n",
    "\n",
    "    Q = np.identity(A.shape[0]);\n",
    "    Q = Q[:,0:k]\n",
    "    Q_old = False\n",
    "    for j in range (1, max_iter):\n",
    "        Q, R = np.linalg.qr(np.dot(A,Q))\n",
    "        if (np.allclose(Q_old, Q)):\n",
    "            break\n",
    "        if (j>1):\n",
    "            Qc = Q_old*Q.transpose();\n",
    "        Q_old = Q\n",
    "    return [np.diag(np.dot(np.dot(np.transpose(Q), A),Q)), Q_old]\n",
    "\n",
    "[a,q]  =normalized_simultaneous_iteration_q(A, 3);\n",
    "print(a);\n",
    "print(q);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='de5'/>\n",
    "### 5.- Power iteration v/s Rayleigh Quotient iteration.\n",
    "##### Comparación de tiempos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Si la matriz es simetrica y positiva definida podemos usar el solve de scipy, pero no es el caso.\n",
    "#import scipy.linalg \n",
    "#sym_solve = lambda A, b: scipy.linalg.solve(A,b,sym_pos=True)\n",
    "iters = 10\n",
    "%timeit power_iteration(sigma_x, max_iter=iters)\n",
    "%timeit rayleigh_quotient_iteration(sigma_x, max_iter=iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a la complejidad de la operación para la matriz de $2500\\times 2500$ se utilizó un número de iteraciones máximo igual a 10.\n",
    "\n",
    "En el computador que se trabajó obtuvimos:\n",
    "```\n",
    "power_iteration:  10 loops, best of 3: 96.4 ms per loop\n",
    "rayleigh_quotient: 1 loops, best of 3: 46.8 s per loop\n",
    "```\n",
    "Como podemos ver *power iteration* es mucho más rapido que *rayleigh quotient*, al contrario de lo que se esperaría teóricamente (la matriz es simetrica así que *rayleigh* debería converger cúbicamente). Esto se debe a que en cada iteración de *rayleigh quotient iteration* se resuelve el sistema de ecuaciones respectivo, en este caso para una matriz con $2500$ variables. Para la resolución se utiliza por defecto `numpy.linalg.solve` que internamente utiliza un algoritmo de complejidad $O(n^3)$, es decir: prácticamente es lo mismo que sacar la inversa en cada paso.\n",
    "\n",
    "Si bien la ventaja de *rayleigh power iteration* es su tasa de convergencia, estos efectos no pueden ser notados a no ser que contemos con un algoritmo que aproveche las caracteristicas de la matriz inicial. Por otro lado el desempeño de *power iteration* es bueno debido a que evita hacer operaciones complejas y, aunque su convergencia es lineal, logra hacer muchas iteraciones en poco tiempo.\n",
    "\n",
    "#### Comparación de memoria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%memit  power_iteration(sigma_x, max_iter=iters)\n",
    "%memit  rayleigh_quotient_iteration(sigma_x, max_iter=iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados en nuestra maquina fueron:\n",
    "```\n",
    "peak memory: 115.98 MiB, increment: 0.03 MiB\n",
    "peak memory: 265.47 MiB, increment: 149.49 MiB\n",
    "```\n",
    "Como podemos notar nuevamente *power iteration* vence a *rayleigh quotient iteration* suponemos debido a las razones nombradas anteriormente, la memoria gastada debe ser en el proceso de resolución de de la matriz.\n",
    "\n",
    "Cabe destacar que en esta ocasión el resultado es el esperado. El proceso de resolución del sistema de ecuaciones gasta más memoria por ciclo. Si la velocidad fuera la correcta esta carácteristica se compensaría con la tasa de convergencia.\n",
    "\n",
    "<div id='de6'/>\n",
    "### 6.- Naive k-eigen finder v/s Clever k-eigen finder v/s k-eigen Normalized Simultaneous Iteration\n",
    "#### Comparación de tiempos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K = [10, 100, 1000]\n",
    "P = 8 #Potencia a elevar\n",
    "for k in K:\n",
    "    print(\"Para k=\", k)\n",
    "    %timeit kEigenFinder(sigma_x, k, max_iter=iters)\n",
    "    %timeit kEigenFinderPP(sigma_x, P, k)\n",
    "    %timeit normalized_simultaneous_iteration_q(sigma_x, k, max_iter=iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado obtenido fue:\n",
    "```\n",
    "Para k= 10\n",
    "1 loops, best of 3: 3.08 s per loop\n",
    "1 loops, best of 3: 45 s per loop\n",
    "1 loops, best of 3: 939 ms per loop\n",
    "Para k= 100\n",
    "1 loops, best of 3: 30.7 s per loop\n",
    "1 loops, best of 3: 1min 43s per loop\n",
    "1 loops, best of 3: 6.84 s per loop\n",
    "Para k= 1000\n",
    "1 loops, best of 3: 5min 5s per loop\n",
    "1 loops, best of 3: 11min 26s per loop\n",
    "1 loops, best of 3: 1min 42s per loop\n",
    "```\n",
    "Podemos notar de la ejecución de los algoritmos que el que obtiene los mejores resultados es el *normalized simultaneous iteration* debido a que la modificación hecha hace que aumentar la cantidad de valores propios buscados solo signifique hacer descomposiciones qr de una matriz más grande. Por otro lado el algoritmo más lento es el `kEigenFinderPP` probablemente debido a errores de implementación. `kEigenFinder` sigue teniendo un desempeño aceptable.\n",
    "\n",
    "De estos resultados podemos notar como afecta la tasa de convergencia y el número de iteraciones en el desempeño de los algoritmos, pues el con mejor tiempo es el que tiene una complejidad computacional mayor.\n",
    "#### Comparación de memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k in K:\n",
    "    print(\"Para k=\", k)\n",
    "    %memit kEigenFinder(sigma_x, k, max_iter=iters)\n",
    "    %memit kEigenFinderPP(sigma_x, P, k)\n",
    "    %memit normalized_simultaneous_iteration_q(sigma_x, k, max_iter=iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtuvo:\n",
    "```\n",
    "Para k= 10\n",
    "peak memory: 250.60 MiB, increment: 146.80 MiB\n",
    "peak memory: 247.93 MiB, increment: 144.11 MiB\n",
    "peak memory: 113.75 MiB, increment: 9.84 MiB\n",
    "Para k= 100\n",
    "peak memory: 259.71 MiB, increment: 153.80 MiB\n",
    "peak memory: 250.01 MiB, increment: 144.11 MiB\n",
    "peak memory: 120.26 MiB, increment: 14.35 MiB\n",
    "Para k= 1000\n",
    "peak memory: 285.01 MiB, increment: 169.56 MiB\n",
    "peak memory: 263.63 MiB, increment: 148.18 MiB\n",
    "peak memory: 218.61 MiB, increment: 95.67 MiB\n",
    "```\n",
    "Como podemos notar nuevamente el algoritmo que tiene el mejor rendimiento es el *normalized simultaneous iteration* por las mismas razones descritas anteriormente. Además vemos como esta vez es el *power iteration el que cae en último* lugar, pues, a pesar de hacer operaciones más simples, debe efectuar muchos más bucles y parte de la memoria no es borrada en el proceso (quizás el recolector de basura no puede detectar correctamente que datos ya no se usan).\n",
    "\n",
    "<div id='de7'/>\n",
    "### 7.- Calculo de todos los valores y vectores propios\n",
    "Para el calculo de los valores y vectores propios utilizaremos ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Gráfico de los dos componentes principales\n",
    "#### b) Gráfico de los tres componentes principales\n",
    "#### c) Componentes necesarios para explicar el 90% de las varianzas de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "Durante este laboratorio se trabajó implementando distintos algoritmos que calculan valores y vectores propios. Se ha estudiado el tiempo que tarda en calcular cada uno de estos algoritmos encontrando cuales de ellos son más rápidos que otros, es decir, tienen menos complejidad computacional.\n",
    "También se ha modificado un algoritmo para que entregue los primeros k valores y vectores propios permitiendo ahorrar bastante cómputo, algo muy importante en matrices de grandes dimensiones.\n",
    "Comparamos algunos algoritmos notando las ventajas que tiene Rayleigh Power Iteration con mejor tasa de convergencia pero con mayor complejidad que Power Iteration. Nuestro algoritmo más rápido fue Normalized Simultaneous Iteration en calcular los k primeros valores y vectores propios, esto viene dado por la complejidad computacional de los algoritmos.\n",
    "Finalmente se puede observar como encontrar los componentes principales que explican la mayor cantidad de las varianzas de los datos nos permite hacer un análisis con muchos menos datos eliminando los que aportan menos información y quedándonos con los que describen mayoritariamente el problema.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "<div id='ref1'\\> [1] [NumPy v1.10 Manual](http://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.solve.html) numpy.linalg.solve. *The solutions are computed using LAPACK routine _gesv*. Revisado 30/10/2015\n",
    "\n",
    "<div id='ref2'\\> [2] [LAPACK Benchmark](http://www.netlib.org/lapack/lug/node71.html). Ver tabla 3.13. Revisado el 30/10/2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
